{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "client=boto3.client('rekognition')\n",
    "#from flatten_json import flatten \n",
    "s3=boto3.resource('s3')\n",
    "target_bucket='demog-output' # please update with the S3 bucket you will be sending files to \n",
    "\n",
    "# Amazon Rekognition\n",
    "def detect_faces(source_image, bucket):\n",
    "    response = client.detect_faces(Image={'S3Object':{'Bucket':bucket,'Name':source_image}},\n",
    "    Attributes=[\n",
    "        'ALL',\n",
    "    ])\n",
    "    return response\n",
    "    \n",
    "\n",
    "def detect_labels(source_image, bucket):\n",
    "    response = client.detect_labels(Image={'S3Object':{'Bucket':bucket,'Name':source_image}},\n",
    "        MaxLabels=8)\n",
    "    return response\n",
    "    \n",
    "def detect_text(source_image, bucket):\n",
    "    response = client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':source_image}},\n",
    "                                 Filters={'WordFilter':{'MinConfidence':80.0}})\n",
    "    return response\n",
    "\n",
    "    \n",
    "# Flatten function so JSON will work nicely with Glue/Apache\n",
    "# Tried import flatten_json from flatten, but not available\n",
    "# This function from https://towardsdatascience.com/flattening-json-objects-in-python-f5343c794b10\n",
    "def flatten(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                flatten(a, name + str(i) + '_')\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "      try:  \n",
    "         source_image=event[\"Records\"][0][\"s3\"][\"object\"][\"key\"]\n",
    "         source_bucket= event[\"Records\"][0][\"s3\"][\"bucket\"][\"name\"]\n",
    "         #print(\"Received event: \" + json.dumps(event, indent=2))\n",
    "         #print(event)\n",
    "         #print(source_image)\n",
    "         #print(source_bucket)\n",
    "         \n",
    "         # Call AWS Rekognition Services \n",
    "         photo_faces = detect_faces(source_image=source_image, bucket=source_bucket)\n",
    "         photo_labels = detect_labels(source_image=source_image, bucket=source_bucket)\n",
    "         photo_text = detect_text(source_image=source_image, bucket=source_bucket)\n",
    "         #print(photo_text)\n",
    "         print(photo_faces)\n",
    "\n",
    "         \n",
    "         # We should now have a dictionary full of labels, and a dictionary full of text\n",
    "\n",
    "         # 1. Process the photo_label dictionary into flattened json, one named detected object per line\n",
    "\n",
    "         j=0\n",
    "         outputstring=\"\"\n",
    "         for r in photo_labels[\"Labels\"]:\n",
    "            photo_labels[\"Labels\"][j][\"Source\"]=source_image\n",
    "            outputstring=outputstring+(json.dumps(flatten(photo_labels[\"Labels\"][j])))+'\\n'\n",
    "            j=j+1\n",
    "         print(outputstring)\n",
    "         # Save the photo_label json file to the target S3 bucket\n",
    "         # ** MAKE SURE THIS IS NOT THE IMAGE SOURCE BUCKET OR YOU MAY GET A LARGE BILL **\n",
    "         if len(outputstring) > 0:\n",
    "            print(\"Labels detected\")\n",
    "            object = s3.Object(target_bucket, \"labels/\" + source_image.split('.')[0] + \".labels.json\")\n",
    "            object.put(Body=outputstring)\n",
    "         else:\n",
    "             print(\"No Labels detected\")\n",
    "         # 2. Process the photo_text dictionary into flattened json, one named detected object per line\n",
    "         j=0\n",
    "         outputstring=\"\"\n",
    "         for r in photo_text[\"TextDetections\"]:\n",
    "           photo_text[\"TextDetections\"][j][\"Source\"]=source_image\n",
    "           outputstring=outputstring+(json.dumps(flatten(photo_text[\"TextDetections\"][j])))+'\\n'\n",
    "           j=j+1\n",
    "         # ** MAKE SURE THIS IS NOT THE IMAGE SOURCE BUCKET OR YOU MAY GET A LARGE BILL **\n",
    "         # Save the photo_text json file to the target S3 bucket\n",
    "         print(outputstring)\n",
    "         if len(outputstring) > 0:\n",
    "             print(\"Text detected\")\n",
    "             object = s3.Object(target_bucket, \"text/\" + source_image.split('.')[0] + \".text.json\")\n",
    "             object.put(Body=outputstring)\n",
    "         else:\n",
    "             print(\"No text detected\")\n",
    "     \n",
    "         \n",
    "         return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.loads(json.dumps(event)) }\n",
    "      except Exception as err:\n",
    "        return {\n",
    "            'statusCode': 400,\n",
    "            'isBase64Encoded':False,\n",
    "            'body': 'Call Failed {0}'.format(err)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
